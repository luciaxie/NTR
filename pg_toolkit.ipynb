{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STRING</th>\n",
       "      <th>initial1</th>\n",
       "      <th>initial1.1</th>\n",
       "      <th>initial1.2</th>\n",
       "      <th>1a</th>\n",
       "      <th>1a.1</th>\n",
       "      <th>1a.2</th>\n",
       "      <th>1b</th>\n",
       "      <th>1b.1</th>\n",
       "      <th>1b.2</th>\n",
       "      <th>...</th>\n",
       "      <th>initial6.2</th>\n",
       "      <th>6a</th>\n",
       "      <th>6a.1</th>\n",
       "      <th>6a.2</th>\n",
       "      <th>6b</th>\n",
       "      <th>6b.1</th>\n",
       "      <th>6b.2</th>\n",
       "      <th>6c</th>\n",
       "      <th>6c.1</th>\n",
       "      <th>6c.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>all</td>\n",
       "      <td>ɔ</td>\n",
       "      <td>a</td>\n",
       "      <td>ɔ+a</td>\n",
       "      <td>l</td>\n",
       "      <td>ll</td>\n",
       "      <td>l+ll</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>cat</td>\n",
       "      <td>k</td>\n",
       "      <td>c</td>\n",
       "      <td>k+c</td>\n",
       "      <td>æ</td>\n",
       "      <td>a</td>\n",
       "      <td>æ+a</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t+t</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028</th>\n",
       "      <td>con</td>\n",
       "      <td>k</td>\n",
       "      <td>c</td>\n",
       "      <td>k+c</td>\n",
       "      <td>ɑ</td>\n",
       "      <td>o</td>\n",
       "      <td>ɑ+o</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>n+n</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4422</th>\n",
       "      <td>hat</td>\n",
       "      <td>h</td>\n",
       "      <td>h</td>\n",
       "      <td>h+h</td>\n",
       "      <td>æ</td>\n",
       "      <td>a</td>\n",
       "      <td>æ+a</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t+t</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     STRING initial1 initial1.1 initial1.2 1a 1a.1  1a.2   1b 1b.1 1b.2  ...  \\\n",
       "218     all        ɔ          a        ɔ+a  l   ll  l+ll  NaN  NaN  NaN  ...   \n",
       "1546    cat        k          c        k+c  æ    a   æ+a    t    t  t+t  ...   \n",
       "2028    con        k          c        k+c  ɑ    o   ɑ+o    n    n  n+n  ...   \n",
       "4422    hat        h          h        h+h  æ    a   æ+a    t    t  t+t  ...   \n",
       "\n",
       "     initial6.2   6a 6a.1 6a.2   6b 6b.1 6b.2   6c 6c.1 6c.2  \n",
       "218         NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1546        NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2028        NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4422        NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[4 rows x 88 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"forR_input.csv\", dtype=str)\n",
    "df = df.apply(lambda col: col.str.lower() if col.dtype == 'object' else col)\n",
    "\n",
    "df = df[df['STRING'].isin(['all', 'cat', 'con', 'hat'])]\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STRING</th>\n",
       "      <th>complexity</th>\n",
       "      <th>initial1</th>\n",
       "      <th>initial1.1</th>\n",
       "      <th>initial1.2</th>\n",
       "      <th>1a</th>\n",
       "      <th>1a.1</th>\n",
       "      <th>1a.2</th>\n",
       "      <th>1b</th>\n",
       "      <th>1b.1</th>\n",
       "      <th>...</th>\n",
       "      <th>initial6.2</th>\n",
       "      <th>6a</th>\n",
       "      <th>6a.1</th>\n",
       "      <th>6a.2</th>\n",
       "      <th>6b</th>\n",
       "      <th>6b.1</th>\n",
       "      <th>6b.2</th>\n",
       "      <th>6c</th>\n",
       "      <th>6c.1</th>\n",
       "      <th>6c.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>all</td>\n",
       "      <td>0</td>\n",
       "      <td>ɔ</td>\n",
       "      <td>a</td>\n",
       "      <td>ɔ+a</td>\n",
       "      <td>l</td>\n",
       "      <td>ll</td>\n",
       "      <td>l+ll</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>cat</td>\n",
       "      <td>0</td>\n",
       "      <td>k</td>\n",
       "      <td>c</td>\n",
       "      <td>k+c</td>\n",
       "      <td>æ</td>\n",
       "      <td>a</td>\n",
       "      <td>æ+a</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028</th>\n",
       "      <td>con</td>\n",
       "      <td>0</td>\n",
       "      <td>k</td>\n",
       "      <td>c</td>\n",
       "      <td>k+c</td>\n",
       "      <td>ɑ</td>\n",
       "      <td>o</td>\n",
       "      <td>ɑ+o</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4422</th>\n",
       "      <td>hat</td>\n",
       "      <td>0</td>\n",
       "      <td>h</td>\n",
       "      <td>h</td>\n",
       "      <td>h+h</td>\n",
       "      <td>æ</td>\n",
       "      <td>a</td>\n",
       "      <td>æ+a</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     STRING  complexity initial1 initial1.1 initial1.2 1a 1a.1  1a.2   1b  \\\n",
       "218     all           0        ɔ          a        ɔ+a  l   ll  l+ll  NaN   \n",
       "1546    cat           0        k          c        k+c  æ    a   æ+a    t   \n",
       "2028    con           0        k          c        k+c  ɑ    o   ɑ+o    n   \n",
       "4422    hat           0        h          h        h+h  æ    a   æ+a    t   \n",
       "\n",
       "     1b.1  ... initial6.2   6a 6a.1 6a.2   6b 6b.1 6b.2   6c 6c.1 6c.2  \n",
       "218   NaN  ...        NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1546    t  ...        NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2028    n  ...        NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4422    t  ...        NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[4 rows x 89 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.insert(1,'complexity', 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pg_df = pd.DataFrame()\n",
    "# all_phonemes = df['initial1'].tolist() + df['1a'].tolist() + df['1b'].tolist()\n",
    "# all_phonemes = list(set(all_phonemes))\n",
    "# pg_df['phoneme'] = all_phonemes\n",
    "\n",
    "# for phoneme in all_phonemes:\n",
    "#     filtered_phoneme_df = df.loc[(df['initial1'] == phoneme) | (df['1a'] == phoneme) | (df['1b'] == phoneme)]\n",
    "#     all_graphemes_for_phoneme_list = filtered_phoneme_df['initial1.1'].tolist() + filtered_phoneme_df['1a.1'].tolist() + filtered_phoneme_df['1b.1'].tolist()\n",
    "#     all_graphemes_for_phoneme_set = set(all_graphemes_for_phoneme_list)\n",
    "#     all_graphemes_for_phoneme_map = {grapheme: all_graphemes_for_phoneme_list.count(grapheme) for grapheme in all_graphemes_for_phoneme_set}\n",
    "#     pg_df.loc[pg_df['phoneme'] == phoneme, 'grapheme_map'] = all_graphemes_for_phoneme_map\n",
    "#     pg_df.loc[pg_df['phoneme'] == phoneme, 'grapheme_count'] = len(filtered_phoneme_df.index)\n",
    "\n",
    "# pg_df\n",
    "\n",
    "\n",
    "# do not use this part:\n",
    "# all_graphemes = df['initial1.1'].tolist() + df['1a.1'].tolist() + df['1b.1'].tolist()\n",
    "# pg_map = {grapheme: 0 for grapheme in all_graphemes}\n",
    "# pg_df['pg_mappings'] = pg_map\n",
    "# pg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phoneme</th>\n",
       "      <th>grapheme</th>\n",
       "      <th>pg_pair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ɔ</td>\n",
       "      <td>a</td>\n",
       "      <td>ɔ+a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k</td>\n",
       "      <td>c</td>\n",
       "      <td>k+c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k</td>\n",
       "      <td>c</td>\n",
       "      <td>k+c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h</td>\n",
       "      <td>h</td>\n",
       "      <td>h+h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l</td>\n",
       "      <td>ll</td>\n",
       "      <td>l+ll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>æ</td>\n",
       "      <td>a</td>\n",
       "      <td>æ+a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ɑ</td>\n",
       "      <td>o</td>\n",
       "      <td>ɑ+o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>æ</td>\n",
       "      <td>a</td>\n",
       "      <td>æ+a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t+t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>n+n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t+t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   phoneme grapheme pg_pair\n",
       "0        ɔ        a     ɔ+a\n",
       "1        k        c     k+c\n",
       "2        k        c     k+c\n",
       "3        h        h     h+h\n",
       "4        l       ll    l+ll\n",
       "5        æ        a     æ+a\n",
       "6        ɑ        o     ɑ+o\n",
       "7        æ        a     æ+a\n",
       "9        t        t     t+t\n",
       "10       n        n     n+n\n",
       "11       t        t     t+t"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg_df = pd.DataFrame()\n",
    "all_phonemes = df['initial1'].tolist() + df['1a'].tolist() + df['1b'].tolist()\n",
    "all_graphemes = df['initial1.1'].tolist() + df['1a.1'].tolist() + df['1b.1'].tolist()\n",
    "all_pg_pairs = df['initial1.2'].tolist() + df['1a.2'].tolist() + df['1b.2'].tolist()\n",
    "pg_df['phoneme'] = all_phonemes\n",
    "pg_df['grapheme'] = all_graphemes\n",
    "pg_df['pg_pair'] = all_pg_pairs\n",
    "pg_df = pg_df.dropna()\n",
    "\n",
    "\n",
    "# unique_phonemes = set(all_phonemes)\n",
    "# for phoneme in unique_phonemes:\n",
    "#     filtered_phoneme_df = pg_df.loc[(pg_df['phoneme'] == phoneme)]\n",
    "#     pg_df.loc[pg_df['phoneme'] == phoneme, 'instances_of_phoneme'] = len(filtered_phoneme_df.index)\n",
    "\n",
    "# unique_graphemes = set(all_graphemes)\n",
    "# for grapheme in unique_graphemes:\n",
    "#     filtered_grapheme_df = pg_df.loc[(pg_df['grapheme'] == grapheme)]\n",
    "#     pg_df.loc[pg_df['grapheme'] == grapheme, 'instances_of_grapheme'] = len(filtered_grapheme_df.index)\n",
    "    \n",
    "pg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p->g for 'ɔ' to 'a': 1.0\n",
      "g->p for 'a' to 'ɔ': 0.3333333333333333\n",
      "ɔ+a frequency: 0.09090909090909091\n"
     ]
    }
   ],
   "source": [
    "def conditional_prob_p_to_g(p, g):\n",
    "    p_g_instances = len((pg_df.loc[(pg_df['phoneme'] == p) & (pg_df['grapheme'] == g)]).index)\n",
    "    p_instances = len((pg_df.loc[(pg_df['phoneme'] == p)]).index)\n",
    "    return p_g_instances / p_instances\n",
    "\n",
    "def conditional_prob_g_to_p(g, p):\n",
    "    p_g_instances = len((pg_df.loc[(pg_df['phoneme'] == p) & (pg_df['grapheme'] == g)]).index)\n",
    "    g_instances = len((pg_df.loc[(pg_df['grapheme'] == g)]).index)\n",
    "    return p_g_instances / g_instances\n",
    "\n",
    "def p_plus_g_frequency(p, g):\n",
    "    p_g_instances = len((pg_df.loc[(pg_df['phoneme'] == p) & (pg_df['grapheme'] == g)]).index)\n",
    "    all_instances = len(pg_df.index)\n",
    "    return p_g_instances / all_instances\n",
    "\n",
    "print(\"p->g for 'ɔ' to 'a':\", conditional_prob_p_to_g('ɔ', 'a'))\n",
    "print(\"g->p for 'a' to 'ɔ':\", conditional_prob_g_to_p('a', 'ɔ'))\n",
    "print(\"ɔ+a frequency:\", p_plus_g_frequency('ɔ', 'a'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_input = input(\"Enter phoneme:\\n\")\n",
    "g_input = input(\"Enter grapheme:\\n\")\n",
    "option = input(\"OPTIONS:\\n1 for p->g conditional probability.\\n2 for g->p conditional probability.\\n3 for p+g frequency.\\nEnter option:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "if option == '1':\n",
    "    print(conditional_prob_p_to_g(p_input, g_input))\n",
    "elif option == '2':\n",
    "    print(conditional_prob_g_to_p(g_input, p_input))\n",
    "elif option == '3':\n",
    "    print(p_plus_g_frequency(p_input, g_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P->G PHONOGRAPHEME CONSISTENCY\n",
    "\n",
    "def calculate_p_to_g_phonographeme_probs(word):\n",
    "    word = word.lower()\n",
    "    p_to_g_probs = []\n",
    "    if word in df['STRING'].values:\n",
    "        word_phonemes = [df.loc[(df['STRING'] == word), 'initial1'].values[0], df.loc[(df['STRING'] == word), '1a'].values[0], df.loc[(df['STRING'] == word), '1b'].values[0]]\n",
    "        word_phonemes = [x for x in word_phonemes if str(x) != 'nan']\n",
    "        word_graphemes = [df.loc[(df['STRING'] == word), 'initial1.1'].values[0], df.loc[(df['STRING'] == word), '1a.1'].values[0], df.loc[(df['STRING'] == word), '1b.1'].values[0]]\n",
    "        word_graphemes = [x for x in word_graphemes if str(x) != 'nan']\n",
    "        for index in range(len(word_phonemes)):\n",
    "            p_to_g_probs.append(conditional_prob_p_to_g(word_phonemes[index], word_graphemes[index]))\n",
    "    return p_to_g_probs\n",
    "    \n",
    "def p_to_g_phonographeme_consistency_median(word):\n",
    "    p_to_g_probs = calculate_p_to_g_phonographeme_probs(word)\n",
    "    if len(p_to_g_probs) != 0:\n",
    "        return statistics.median(p_to_g_probs)\n",
    "    return None\n",
    "\n",
    "def p_to_g_phonographeme_consistency_mean(word):\n",
    "    p_to_g_probs = calculate_p_to_g_phonographeme_probs(word)\n",
    "    if len(p_to_g_probs) != 0:\n",
    "        return statistics.mean(p_to_g_probs)\n",
    "    return None\n",
    "\n",
    "def p_to_g_phonographeme_consistency_max(word):\n",
    "    p_to_g_probs = calculate_p_to_g_phonographeme_probs(word)\n",
    "    if len(p_to_g_probs) != 0:\n",
    "        return max(p_to_g_probs)\n",
    "    return None\n",
    "\n",
    "def p_to_g_phonographeme_consistency_min(word):\n",
    "    p_to_g_probs = calculate_p_to_g_phonographeme_probs(word)\n",
    "    if len(p_to_g_probs) != 0:\n",
    "        return min(p_to_g_probs)\n",
    "    return None\n",
    "\n",
    "def p_to_g_phonographeme_consistency_distribution_quantile(word, q): # e.g. q = 0.25 for Q1, q = 0.7 for 70th percentile\n",
    "    p_to_g_probs = calculate_p_to_g_phonographeme_probs(word)\n",
    "    if len(p_to_g_probs) != 0 and q >= 0 and q <= 100:\n",
    "        return np.quantile(p_to_g_probs, q)\n",
    "    return None\n",
    "\n",
    "def p_to_g_phonographeme_consistency_IQR(word):\n",
    "    return p_to_g_phonographeme_consistency_distribution_quantile(word, 0.75) - p_to_g_phonographeme_consistency_distribution_quantile(word, 0.25)\n",
    "\n",
    "def p_to_g_phonographeme_consistency_range(word):\n",
    "    return p_to_g_phonographeme_consistency_max(word) - p_to_g_phonographeme_consistency_min(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "word_input = input(\"P->G PHONOGRAPHEME CONSISTENCY\\nEnter word:\\n\")\n",
    "if word_input.lower() not in df['STRING'].values:\n",
    "    print(\"Word not found. Exiting.\")\n",
    "else:\n",
    "    p_to_g_photographeme_consistency_option = input(\"OPTIONS:\\n1 for median.\\n2 for mean.\\n3 for max.\\n4 for min.\\nEnter option:\")\n",
    "    \n",
    "    if p_to_g_photographeme_consistency_option == '1':\n",
    "        print(p_to_g_phonographeme_consistency_median(word_input))\n",
    "    elif p_to_g_photographeme_consistency_option == '2':\n",
    "        print(p_to_g_phonographeme_consistency_mean(word_input))\n",
    "    elif p_to_g_photographeme_consistency_option == '3':\n",
    "        print(p_to_g_phonographeme_consistency_max(word_input))\n",
    "    elif p_to_g_photographeme_consistency_option == \"4\":\n",
    "        print(p_to_g_phonographeme_consistency_min(word_input))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G->P PHONOGRAPHEME CONSISTENCY\n",
    "\n",
    "def calculate_g_to_p_phonographeme_probs(word):\n",
    "    word = word.lower()\n",
    "    g_to_p_probs = []\n",
    "    if word in df['STRING'].values:\n",
    "        word_phonemes = [df.loc[(df['STRING'] == word), 'initial1'].values[0], df.loc[(df['STRING'] == word), '1a'].values[0], df.loc[(df['STRING'] == word), '1b'].values[0]]\n",
    "        word_phonemes = [x for x in word_phonemes if str(x) != 'nan']\n",
    "        word_graphemes = [df.loc[(df['STRING'] == word), 'initial1.1'].values[0], df.loc[(df['STRING'] == word), '1a.1'].values[0], df.loc[(df['STRING'] == word), '1b.1'].values[0]]\n",
    "        word_graphemes = [x for x in word_graphemes if str(x) != 'nan']\n",
    "        for index in range(len(word_phonemes)):\n",
    "            g_to_p_probs.append(conditional_prob_g_to_p(word_graphemes[index], word_phonemes[index]))\n",
    "    return g_to_p_probs\n",
    "    \n",
    "def g_to_p_phonographeme_consistency_median(word):\n",
    "    g_to_p_probs = calculate_g_to_p_phonographeme_probs(word)\n",
    "    if len(g_to_p_probs) != 0:\n",
    "        return statistics.median(g_to_p_probs)\n",
    "    return None\n",
    "\n",
    "def g_to_p_phonographeme_consistency_mean(word):\n",
    "    g_to_p_probs = calculate_g_to_p_phonographeme_probs(word)\n",
    "    if len(g_to_p_probs) != 0:\n",
    "        return statistics.mean(g_to_p_probs)\n",
    "    return None\n",
    "\n",
    "def g_to_p_phonographeme_consistency_max(word):\n",
    "    g_to_p_probs = calculate_g_to_p_phonographeme_probs(word)\n",
    "    if len(g_to_p_probs) != 0:\n",
    "        return max(g_to_p_probs)\n",
    "    return None\n",
    "\n",
    "def g_to_p_phonographeme_consistency_min(word):\n",
    "    g_to_p_probs = calculate_g_to_p_phonographeme_probs(word)\n",
    "    if len(g_to_p_probs) != 0:\n",
    "        return min(g_to_p_probs)\n",
    "    return None\n",
    "\n",
    "def g_to_p_phonographeme_consistency_distribution_quantile(word, q): # e.g. q = 0.25 for Q1, q = 0.7 for 70th percentile\n",
    "    g_to_p_probs = calculate_g_to_p_phonographeme_probs(word)\n",
    "    if len(g_to_p_probs) != 0 and q >= 0 and q <= 100:\n",
    "        return np.quantile(g_to_p_probs, q)\n",
    "    return None\n",
    "\n",
    "def g_to_p_phonographeme_consistency_IQR(word):\n",
    "    return g_to_p_phonographeme_consistency_distribution_quantile(word, 0.75) - g_to_p_phonographeme_consistency_distribution_quantile(word, 0.25)\n",
    "\n",
    "def p_to_g_phonographeme_consistency_range(word):\n",
    "    return g_to_p_phonographeme_consistency_max(word) - g_to_p_phonographeme_consistency_min(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_input = input(\"G->P PHONOGRAPHEME CONSISTENCY\\nEnter word:\\n\")\n",
    "if word_input.lower() not in df['STRING'].values:\n",
    "    print(\"Word not found. Exiting.\")\n",
    "else:\n",
    "    g_to_p_photographeme_consistency_option = input(\"OPTIONS:\\n1 for median.\\n2 for mean.\\n3 for max.\\n4 for min.\\nEnter option:\")\n",
    "    \n",
    "    if g_to_p_photographeme_consistency_option == '1':\n",
    "        print(g_to_p_phonographeme_consistency_median(word_input))\n",
    "    elif g_to_p_photographeme_consistency_option == '2':\n",
    "        print(g_to_p_phonographeme_consistency_mean(word_input))\n",
    "    elif g_to_p_photographeme_consistency_option == '3':\n",
    "        print(g_to_p_phonographeme_consistency_max(word_input))\n",
    "    elif g_to_p_photographeme_consistency_option == \"4\":\n",
    "        print(g_to_p_phonographeme_consistency_min(word_input))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
